{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ip = str(json.load(open('/usr/local/Desktop/paper1/paper1/config/config-' + suffix + '.json'))['ip_local'])\n",
    "file_name = 'lstm'+str(ip).split('.')[-1]\n",
    "dataframe = pd.read_csv('/usr/local/Desktop/' + file_name + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền Xử Lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.drop(['_id','byteSent','byteReceived','IpSDN','src', 'dst'], axis=1, inplace=True)\n",
    "dataframe.drop(['src', 'dst'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xu ly mat can bang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5851\n",
      "38860\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_minority = dataframe[dataframe['label'] ==1]\n",
    "df_majority = dataframe[dataframe['label'] ==0]\n",
    "\n",
    "print(len(df_minority))\n",
    "print(len(df_majority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples= 20000)\n",
    "\n",
    "#Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples= 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa204090b90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_up_down_sampled = pd.concat([df_majority_downsampled, df_minority_upsampled])\n",
    "df_up_down_sampled['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_up_down_sampled['label']\n",
    "X = df_up_down_sampled.drop(columns='label')\n",
    "y_set = y.values\n",
    "X_set = X.values.astype('float32')\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_set = scaler.fit_transform(X_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_set, y_set, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay đổi shape của tập X\n",
    "time_steps = 1\n",
    "input_train_lstm = train_X.reshape( train_X.shape[0], time_steps, train_X.shape[1] )\n",
    "\n",
    "input_test_lstm = test_X.reshape(   test_X.shape[0], time_steps, test_X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 1, 64)             17664     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 1, 128)            98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,953\n",
      "Trainable params: 165,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.7885\n",
      "Epoch 1: accuracy improved from -inf to 0.78850, saving model to lstm200.hdf5\n",
      "875/875 [==============================] - 6s 5ms/step - loss: 0.5748 - accuracy: 0.7885\n",
      "Epoch 2/100\n",
      "870/875 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.9078\n",
      "Epoch 2: accuracy improved from 0.78850 to 0.90782, saving model to lstm200.hdf5\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.2979 - accuracy: 0.9078\n",
      "Epoch 3/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9293\n",
      "Epoch 3: accuracy improved from 0.90782 to 0.92925, saving model to lstm200.hdf5\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.1913 - accuracy: 0.9293\n",
      "Epoch 4/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9438\n",
      "Epoch 4: accuracy improved from 0.92925 to 0.94393, saving model to lstm200.hdf5\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.1420 - accuracy: 0.9439\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 6.8840 - accuracy: 0.5480\n",
      "Epoch 5: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 6.8840 - accuracy: 0.5480\n",
      "Epoch 6/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.7108 - accuracy: 0.5001\n",
      "Epoch 6: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 7/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7080 - accuracy: 0.5003\n",
      "Epoch 7: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 8/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7119 - accuracy: 0.5000\n",
      "Epoch 8: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 9/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7075 - accuracy: 0.5003\n",
      "Epoch 9: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 10/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7070 - accuracy: 0.5004\n",
      "Epoch 10: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 11/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7164 - accuracy: 0.4997\n",
      "Epoch 11: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 12/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7119 - accuracy: 0.5000\n",
      "Epoch 12: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 13/100\n",
      "870/875 [============================>.] - ETA: 0s - loss: 7.7069 - accuracy: 0.5004\n",
      "Epoch 13: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 14: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 15/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7114 - accuracy: 0.5001\n",
      "Epoch 15: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 16/100\n",
      "870/875 [============================>.] - ETA: 0s - loss: 7.7058 - accuracy: 0.5004\n",
      "Epoch 16: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 17/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 17: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 18: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 19/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5001\n",
      "Epoch 19: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 20/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.7091 - accuracy: 0.5002\n",
      "Epoch 20: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 21/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7064 - accuracy: 0.5004\n",
      "Epoch 21: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 22/100\n",
      "864/875 [============================>.] - ETA: 0s - loss: 7.7036 - accuracy: 0.5006\n",
      "Epoch 22: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 23/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7041 - accuracy: 0.5005\n",
      "Epoch 23: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 24/100\n",
      "872/875 [============================>.] - ETA: 0s - loss: 7.7086 - accuracy: 0.5003\n",
      "Epoch 24: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 25/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.7158 - accuracy: 0.4998\n",
      "Epoch 25: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 26/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7069 - accuracy: 0.5004\n",
      "Epoch 26: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 27: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 28: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 29: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 30/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5001\n",
      "Epoch 30: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 31/100\n",
      "868/875 [============================>.] - ETA: 0s - loss: 7.7064 - accuracy: 0.5004\n",
      "Epoch 31: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 32/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 7.7081 - accuracy: 0.5003\n",
      "Epoch 32: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 33/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 7.7119 - accuracy: 0.5000\n",
      "Epoch 33: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 34/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7114 - accuracy: 0.5001\n",
      "Epoch 34: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 35/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 7.7092 - accuracy: 0.5002\n",
      "Epoch 35: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 36/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.7091 - accuracy: 0.5002\n",
      "Epoch 36: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 37: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 38/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.6992 - accuracy: 0.5009\n",
      "Epoch 38: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 39/100\n",
      "868/875 [============================>.] - ETA: 0s - loss: 7.7086 - accuracy: 0.5003\n",
      "Epoch 39: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 40/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7081 - accuracy: 0.5003\n",
      "Epoch 40: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 41/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7080 - accuracy: 0.5003\n",
      "Epoch 41: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 42: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 43/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7136 - accuracy: 0.4999\n",
      "Epoch 43: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 44/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7092 - accuracy: 0.5002\n",
      "Epoch 44: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 45/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7130 - accuracy: 0.5000\n",
      "Epoch 45: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 46: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 47/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5001\n",
      "Epoch 47: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 48/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7014 - accuracy: 0.5007\n",
      "Epoch 48: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 49/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7081 - accuracy: 0.5003\n",
      "Epoch 49: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 50/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7114 - accuracy: 0.5001\n",
      "Epoch 50: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 51/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 7.7092 - accuracy: 0.5002\n",
      "Epoch 51: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 52/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.7075 - accuracy: 0.5003\n",
      "Epoch 52: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 53/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 53: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 54/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7175 - accuracy: 0.4997\n",
      "Epoch 54: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 55/100\n",
      "863/875 [============================>.] - ETA: 0s - loss: 7.7086 - accuracy: 0.5003\n",
      "Epoch 55: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 56/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7081 - accuracy: 0.5003\n",
      "Epoch 56: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 57/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7181 - accuracy: 0.4996\n",
      "Epoch 57: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 58: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 59/100\n",
      "868/875 [============================>.] - ETA: 0s - loss: 7.7069 - accuracy: 0.5004\n",
      "Epoch 59: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 60: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 61/100\n",
      "868/875 [============================>.] - ETA: 0s - loss: 7.7019 - accuracy: 0.5007\n",
      "Epoch 61: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 62/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5001\n",
      "Epoch 62: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 63/100\n",
      "872/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 63: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 64/100\n",
      "868/875 [============================>.] - ETA: 0s - loss: 7.7147 - accuracy: 0.4999\n",
      "Epoch 64: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 65/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 65: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 66/100\n",
      "872/875 [============================>.] - ETA: 0s - loss: 7.7064 - accuracy: 0.5004\n",
      "Epoch 66: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 67: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 68/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 68: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 69/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7136 - accuracy: 0.4999\n",
      "Epoch 69: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 70/100\n",
      "872/875 [============================>.] - ETA: 0s - loss: 7.7114 - accuracy: 0.5001\n",
      "Epoch 70: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 71/100\n",
      "868/875 [============================>.] - ETA: 0s - loss: 7.7119 - accuracy: 0.5000\n",
      "Epoch 71: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 72/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7147 - accuracy: 0.4999\n",
      "Epoch 72: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 73: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 74/100\n",
      "863/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 74: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 75/100\n",
      "873/875 [============================>.] - ETA: 0s - loss: 7.7048 - accuracy: 0.5005\n",
      "Epoch 75: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 76: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 77/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7081 - accuracy: 0.5003\n",
      "Epoch 77: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 78/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7058 - accuracy: 0.5004\n",
      "Epoch 78: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 79/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7086 - accuracy: 0.5003\n",
      "Epoch 79: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 80/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7064 - accuracy: 0.5004\n",
      "Epoch 80: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 81/100\n",
      "860/875 [============================>.] - ETA: 0s - loss: 7.7046 - accuracy: 0.5005\n",
      "Epoch 81: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 82/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7064 - accuracy: 0.5004\n",
      "Epoch 82: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 83/100\n",
      "861/875 [============================>.] - ETA: 0s - loss: 7.7119 - accuracy: 0.5000\n",
      "Epoch 83: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 84/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7114 - accuracy: 0.5001\n",
      "Epoch 84: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 85/100\n",
      "865/875 [============================>.] - ETA: 0s - loss: 7.7030 - accuracy: 0.5006\n",
      "Epoch 85: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 86/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.7091 - accuracy: 0.5002\n",
      "Epoch 86: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 87/100\n",
      "872/875 [============================>.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5001\n",
      "Epoch 87: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 88/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7086 - accuracy: 0.5003\n",
      "Epoch 88: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 89/100\n",
      "870/875 [============================>.] - ETA: 0s - loss: 7.7108 - accuracy: 0.5001\n",
      "Epoch 89: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 90/100\n",
      "866/875 [============================>.] - ETA: 0s - loss: 7.6986 - accuracy: 0.5009\n",
      "Epoch 90: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 91/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7081 - accuracy: 0.5003\n",
      "Epoch 91: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 92/100\n",
      "874/875 [============================>.] - ETA: 0s - loss: 7.7092 - accuracy: 0.5002\n",
      "Epoch 92: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 93/100\n",
      "864/875 [============================>.] - ETA: 0s - loss: 7.7147 - accuracy: 0.4999\n",
      "Epoch 93: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 94/100\n",
      "871/875 [============================>.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5001\n",
      "Epoch 94: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 95/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7097 - accuracy: 0.5002\n",
      "Epoch 95: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 96/100\n",
      "869/875 [============================>.] - ETA: 0s - loss: 7.7075 - accuracy: 0.5003\n",
      "Epoch 96: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 97/100\n",
      "860/875 [============================>.] - ETA: 0s - loss: 7.7198 - accuracy: 0.4995\n",
      "Epoch 97: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 98/100\n",
      "867/875 [============================>.] - ETA: 0s - loss: 7.7047 - accuracy: 0.5005\n",
      "Epoch 98: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 99/100\n",
      "861/875 [============================>.] - ETA: 0s - loss: 7.7108 - accuracy: 0.5001\n",
      "Epoch 99: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 7.7086 - accuracy: 0.5002\n",
      "Epoch 100/100\n",
      "872/875 [============================>.] - ETA: 0s - loss: 7.7086 - accuracy: 0.5003\n",
      "Epoch 100: accuracy did not improve from 0.94393\n",
      "875/875 [==============================] - 3s 4ms/step - loss: 7.7086 - accuracy: 0.5002\n"
     ]
    }
   ],
   "source": [
    "# #Building the LSTM Model\n",
    "lstm = Sequential()\n",
    "# unit = hidden state\n",
    "lstm.add(LSTM(units=64, input_shape=(time_steps, input_train_lstm.shape[2]), activation='relu', return_sequences=True))\n",
    "\n",
    "lstm.add(LSTM(units=128, activation='relu', return_sequences=True))\n",
    "\n",
    "lstm.add(LSTM(units=64, activation='relu', return_sequences=False))\n",
    "\n",
    "# lop dau vao hinh tron\n",
    "lstm.add(Dense(1)) \n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "lstm.summary()\n",
    "file_name = file_name + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='accuracy', save_best_only=True, mode='auto', period=1, verbose=1)\n",
    "# early = EarlyStopping(monitor='accuracy')\n",
    "epoch=100\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "history = lstm.fit(input_train_lstm,\n",
    "                   train_y,\n",
    "                   epochs=epoch,\n",
    "                   verbose=1,\n",
    "                   callbacks=[checkpoint])\n",
    "                   \n",
    "print('Total training time: ', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e5d662191a2770e65cfd5912a2c03b3e5b93f8f5758621f69c9112618d6fd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
